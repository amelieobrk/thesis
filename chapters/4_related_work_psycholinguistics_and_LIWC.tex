\section{Linguistic Inquiry and Word Count (LIWC)}
%Ziel: Leser:innen verstehen, wie psychologische Merkmale sprachlich messbar sind.
%Einführung in LIWC: Funktionsweise, Wortkategorien


Linguistic Inquiry and Word Count (LIWC) was originally developed in the early 1990s by James W. Pennebaker and colleagues as a theory-driven tool for the analysis of written and spoken language~\cite{tausczik2010psychological}. 
The main goal of LIWC is to extract insights into psychological states, attitudes, and personality traits of the writer based on a predefined dictionary that maps words to psychologically meaningful linguistic categories. LIWC analyzes text by counting the frequency of words in these categories, providing a quantitative representation of the language used. This allows researchers to draw conclusions about the psychological and social dimensions of the text.
The construction of the LIWC dictionary and category system followed an iterative process: initially, relevant words were selected based on psychological theory and expert evaluation. These were then revised, adapted, and psychometrically validated through continuous testing and updated over time in response to new research findings and computational methods. The LIWC dictionary has been continuously refined, with its most recent version released in 2022. \parencite{pennebaker2022liwc}.


\subsection{LIWC-22 Categories}
The main categories in LIWC-22 are structured as follows:

\begin{itemize}
    \item \textbf{Linguistic dimensions:} Cover syntactic and functional aspects such as personal pronouns (e.g., first person singular/plural), articles, auxiliary verbs, verb tenses, negations, and other grammatical features.
    \item \textbf{Psychological processes:}
        \begin{itemize}
            \item \textit{Affective processes:} Positive and negative emotions, anger, anxiety, sadness, and swearing.
            \item \textit{Cognitive processes:} Insight, causation, discrepancies, tentativeness, certainty, differentiation, memory, and analytical thinking.
            \item \textit{Social processes:} Family, friends, references to males/females, group membership, communication terms, politeness, moralization, prosocial behavior.
        \end{itemize}
    \item \textbf{Personal concerns:} Work, money, religion, home, leisure, sexuality, politics, ethnicity, and technology.
    \item \textbf{Biological/physical processes:} Body, health, illness, wellness, mental states, food, substances, death.
    \item \textbf{Cultural and digital phenomena:} Culture-related categories (such as politics, ethnicity), netspeak, conversation markers, and emojis.
    \item \textbf{Summary variables:} Analytic thinking, clout (social status), authenticity, and emotional tone---these provide higher-order, composite scores derived from subcategory frequencies.
    \item \textbf{Other metrics:} Additional features such as total word count, average words per sentence, dictionary word proportion, and the percentage of "big words" (long words) are also included.
\end{itemize}

Each word in the dictionary may belong to multiple categories simultaneously. For example, the word ``cry'' is counted within \textit{negative emotion}, \textit{sadness}, and \textit{past tense} categories. LIWC's multidimensional approach enables detailed quantitative assessment of the psychological and social dimensions hidden within texts, making it a valuable tool across psychology, social science, computer science, and digital communication research~\cite{pennebaker2022liwc}.



\subsection{Psychometric Profiling with LIWC}

LIWC has become a cornerstone of psychological and behavioral language research due to its ability to extract psychologically meaningful dimensions from text. As Tausczik and Pennebaker~\cite{tausczik2010psychological} emphasize, LIWC bridges the gap between language and psychology by mapping linguistic usage onto cognitive, emotional, and social constructs. This enables researchers to quantify and interpret even subtle psychological processes on a large scale. This capability makes LIWC indispensable across a variety of fields. For example, in forensic psychology, different LIWC categories facilitate the detection of deceptive patterns in communication. Fornaciari and Poesio~\cite{fornaciari2013automatic} successfully applied LIWC to distinguish between truthful and fabricated statements in forensic transcripts, identifying linguistic markers of deception. %% approved

A recent study by Glasauer and Alexandrowicz~\cite{glasauer2022bigfive} illustrates LIWC’s utility for objective personality assessment. Using expressive writing samples from 124 participants, they modeled Big Five traits as latent constructs predicted by LIWC categories. While correlations with traditional self-reports were moderate—particularly for Neuroticism, Conscientiousness, and Openness—the approach showed promising model fits and validity. Similarly, Farnadi et al.~\cite{farnadi2018user} demonstrated the effectiveness of LIWC for personality recognition in a large-scale multimodal setting. They extracted 88 LIWC-based features from Facebook status updates and compared them to alternative text representations such as n-grams and word embeddings (GloVe, fastText). LIWC features consistently outperformed these linguistic cues and were therefore used as the primary textual representation in their deep neural network models. This allowed the authors to capture  psycholinguistically grounded indicators of personality, particularly for the Big Five traits, while integrating them with visual and relational data. Together, these studies show the ability of LIWC to capture personality-related language patterns and highlight its usefulness for unobtrusive, scalable personality profiling in both psychological and forensic contexts. %aproved

The relevance of LIWC has further increased through its integration into modern machine learning pipelines. Recent work, such as that by Kilic et al.~\cite{yakut-kilic-pan-2022-incorporating}, demonstrates that LIWC-based features not only enhance the predictive performance of neural networks but also provide interpretable insights into the linguistic markers underlying complex behavioral predictions. Thus, LIWC serves as both a theoretical and practical bridge between classical psycholinguistic analysis and the current state of computational modeling. %% das war mal ding et al aber ist approved


\section{LIWC in Cybergrooming Research}
 As highlighted in the comprehensive interdisciplinary review by An et al.~\cite{an2025cybergrooming}, LIWC is among the most frequently utilized psycholinguistic tools in computational cybergrooming detection pipelines. Its ability to map word usage onto psychologically meaningful constructs has greatly improved the interpretability and effectiveness of machine learning models, supporting both risk analysis and offender profiling. %% approved
 
 A central application of LIWC (Linguistic Inquiry and Word Count) lies in the linguistic characterization of grooming stages in chat-based conversations between adults and minors. Gupta et al.~\cite{gupta2012characterizingpedophileconversationsinternet} were among the first to segment annotated pedophile chat logs based on grooming theory and to use LIWC for creating psycholinguistic profiles of individual grooming phases. Their results showed that certain LIWC categories such as \textit{social processes}, \textit{family}, or \textit{sexual} terms exhibit distinctive frequency patterns along the grooming timeline. Cano et al.~\cite{Cano2014} confirmed these findings by demonstrating that integrating LIWC-derived features into machine learning models significantly improves the detection of grooming activities and phases, particularly in comparison to simple lexical baselines. %%% approved

More recent studies have extended the application of LIWC beyond offender profiling. Guo et al.~\cite{guo2023text}, for example, examined psychological vulnerability markers of potential victims and quantified them using LIWC categories. %wichtig
 They found that personality traits and social support dimensions derived from LIWC robustly distinguish between more and less vulnerable minors.  %wichtig ende 
 Another empirical study by Broome et al.~\cite{broome2020psycholinguistic} involved focus groups with police and correctional officers to identify relevant LIWC categories (e.g., affective, social, cognitive, biological processes), whose salience was then validated through the analysis of authentic grooming chats. The findings emphasized that grooming discourse is often not solely characterized by overtly sexual content but also by frequent social bonding signals and a focus on the present. %%approved


The review by An et al.~\cite{an2025cybergrooming} further corroborate the high relevance of LIWC in grooming research. The authors highlight three main advantages:
\begin{itemize}
    \item LIWC provides interpretable and theory-driven language features that can be effectively integrated into scalable machine learning models,
    \item It supports phase detection and offender profiling through the quantitative mapping of conversational structure,
    \item It enables cross-platform and cross-linguistic analysis due to its validated and standardized category framework.
\end{itemize} %%approved

An et al.~\cite{an2025cybergrooming} further emphasize that LIWC categories—such as affective states, social processes, biological cues, and cognitive markers—are not arbitrarily selected but have been empirically validated through repeated application in leading computational and social science studies. %%approved


\subsection{Key psychometric LIWC Features in Grooming} \label{psychometric_liwc_features_in_grooming}
The following LIWC dimensions have consistently proven to be most informative in the context of cybergrooming detection and linguistic analysis\cite{gupta2012characterizingpedophileconversationsinternet,broome2020psycholinguistic,an2025cybergrooming}):
\begin{itemize}
    \item \textbf{Affective processes}: positive/negative emotion, sadness, anxiety
    \item \textbf{Social processes}: family, friends, communication, group references
    \item \textbf{Cognitive processes}: insight, certainty, tentative language, causation
    \item \textbf{Biological processes}: body, sexual keywords
    \item \textbf{Drives and informal language}: risk, reward, netspeak, swear words
\end{itemize} %%approved

In summary, LIWC offers a validated, scalable, and interpretable set of psycholinguistic features that has proven  effective both for descriptive analyses and as input variables for machine learning models in cybergrooming research~\cite{an2025cybergrooming, gupta2012characterizingpedophileconversationsinternet, Cano2014, guo2023text,broome2020psycholinguistic}. Its widespread adoption and continuous methodological refinement make it an important resource for understanding, detecting, and ultimately preventing online grooming.

\section{Explainable AI with SHAP}

While deep learning models achieve remarkable performance in natural language processing tasks, their decision-making processes often remain obscure. This is particularly relevant for deep neural networks such as transformer-based language models, as such models act as \emph{black boxes}: due to millions of parameters and complex, non-linear relationships, it is difficult to directly interpret the decision logic~\cite{bilal2025}, \cite{ali2022}. The field of Explainable AI (XAI) seeks to address this by developing methods that make model behavior interpretable and comprehensible to human users. %% approved
One of the key techniques in XAI is the use of feature attribution methods, which assign importance scores to individual input features based on their contribution to the model's output. This allows users to understand which aspects of the input data most strongly influence the model's predictions. Two widely used methods for this purpose are SHAP (Shapley Additive explanations) and LIME (Local Interpretable Model-agnostic Explanations). Both approaches aim to explain individual model predictions by quantifying the importance of input features, yet they differ significantly in their underlying methodology and scope.

\textbf{SHAP} is grounded in cooperative game theory and builds on the concept of \emph{Shapley values}~\cite{lundberg2017shap}. It treats the prediction task as a game in which each input feature contributes to the final outcome. For a given model and instance, SHAP calculates how the model's prediction changes when a specific feature is added or removed from all possible subsets of features. The resulting Shapley value of a feature is its average marginal contribution across all possible feature combinations. This makes SHAP a mathematically sound and globally consistent attribution method.

One of SHAP's core strengths is its satisfaction of desirable properties such as:

\begin{itemize}
    \item \textbf{Fairness}: Features that have no impact on the model output receive a SHAP value of zero.
    \item \textbf{Consistency}: If a model is changed such that a feature contributes more to the output, its SHAP value does not decrease.
    \item \textbf{Additivity}: The sum of all SHAP values plus a base value (often the average model output) exactly equals the model prediction for the instance.

\end{itemize}
SHAP can be applied to any machine learning model, including complex deep learning architectures, making it a versatile tool for interpreting model behavior across different domains. \textbf{However, calculating exact Shapley values can be computationally expensive, especially for models with many features \cite{rozemberczki2022shapley}, \cite{aas2021explaining}. Also, it is important to note that SHAP explanations can be affected by class imbalance. In strongly skewed datasets, the attributions may be dominated by the majority class, potentially obscuring signals from the minority class. Therefore, balancing the data or carefully designing the background distribution is recommended to ensure faithful and interpretable explanations~\cite{liu2022balancedbackgroundexplanationdata}, \cite{chen2024interpretable}.
}
 

\section{Integrating Psycholinguistic Features and Explainable AI for Enhanced Grooming Detection}
Previous approaches to detecting cyber grooming have primarily focused on linguistic features for the early identification of problematic communication~\cite{yakut-kilic-pan-2022-incorporating}, but have systematically neglected the integration of validated psychological frameworks into explainable AI approaches~\cite{broome2020psycholinguistic}. Recent research demonstrates that combining LIWC features with Transformer-based models and SHAP can significantly enhance both the interpretability and predictive performance of models.

Preiss and Chen \cite{preiss-chen-2024-incorporating} show that integrating LIWC-22 into a Mental-RoBERTa classifier, combined with SHAP analyses, enables reliable extraction of psycholinguistically relevant text segments. Similar findings are reported by Wewelwala et al. \cite{wewelwala2025hybrid} in clinical emotion analysis: combining ClinicalBERT with LIWC/NRC and SHAP yielded complementary contributions, with the Transformer providing around 68\% of the predictive signal and LIWC/NRC contributing the remaining 32\%. These features offered additional psychological insights and improved interpretability.

Miah et. al.\cite{miah-etal-2011-detection} and Salminen et. al.~\cite{salminen2025} extend these findings in a related, but for this work particularly relevant, context: the detection of toxic and harmful online communication. Both studies show that combining contextual embeddings (BERT variants) with LIWC-based psycholinguistic features leads to more robust predictions and clearer, psychologically grounded explanations, even in complex, multimodal chat data.

Despite these advances, a significant research gap remains in the domain of cyber grooming detection: the fusion of psycholinguistic features with modern language models, and their transparent evaluation using SHAP, has not yet been systematically implemented.

\textbf{This work addresses this gap by combining Transformer-based text representations (BERT) with LIWC features and applying SHAP to quantify the contribution of both feature sets to model predictions. The aim is to significantly improve the detection performance of cyber grooming while enhancing explainability through psychologically grounded, transparent model interpretations, thereby establishing a methodological foundation for future applications.}




\begin{comment}
    Explainability in Transformer-based Grooming Detection
    – Wie bisherige Arbeiten XAI nutzen (z. B. Ribeiro et al. 2024, Broome et al., Mersha et al.)
    – Warum psycholinguistische Features (LIWC) besonders geeignet sind: sie sind menschenverständlich, validiert und direkt interpretierbar
    – Kombination von SHAP + LIWC als erklärbare Pipeline


Your Contribution
– Ziel deiner Arbeit: mit LIWC die Erklärbarkeit steigern
– Hinweis, dass du in Kapitel 5/6/7 auf die empirischen Ergebnisse dieser Kombination zurückkommst
\end{comment}


%%% The combination of LIWC’s validated feature set and its capacity for interpretability makes it particularly valuable for explainable artificial intelligence (XAI), where understanding model decisions is essent


%%%%% For example, Guo et al.~\cite{guo2023textmining} demonstrated how LIWC features can improve the explainability of machine learning models in the context of text mining and social media analysis. %% approved




\begin{comment}
    



Explainability-Methoden wie \textbf{SHAP} und \textbf{LIME} ermöglichen es, Entscheidungen komplexer Modelle \emph{nachvollziehbar} zu machen. Bei kombinierten RoBERTa+LIWC-Modellen kann analysiert werden, welche psycholinguistischen Kategorien entscheidend für die Klassifikation ``Grooming'' waren.

Beispiele:
\begin{itemize}
    \item \textbf{Mehta et al. (2021)}: SHAP-Visualisierungen der wichtigsten LIWC-Kategorien pro Persönlichkeitsklasse.
    \item \textbf{Shahzad et al. (2024)}: LIME zeigt Schlüsselwörter für Hate-Speech-Klassifikation; übertragbar auf Grooming.
\end{itemize}
% Warum erklärbare Modelle wichtig sind, gerade bei sensiblen Themen wie Grooming Detection.
%Was ist Explainability? Unterschied zu Interpretierbarkeit
%SHAP: Konzept & Beispielanwendung
%LIME: Idee & Visualisierung
%Anwendung auf LIWC+RoBERTa Modelle



für mich wichtig:
1. Baseline ist wichtig
Ein starkes Baseline-Modell (RoBERTa-only) ist ein Geschenk: Es zeigt, dass dein Preprocessing, Datenset und Task solide aufgebaut sind. Jetzt kannst du in deiner Arbeit untersuchen:

➤ Wann versagt RoBERTa allein? Wo liegen die Fehler?
➤ Wo könnten psycholinguistische Merkmale doch noch helfen?

2. Explainability als legitimer Mehrwert
Auch wenn die Performance schon hoch ist, kann LIWC dir helfen, die Entscheidungen des Modells zu erklären – was in sensiblen Themen wie Cybergrooming zentral ist.

➤ RoBERTa kann sagen, „dieser Chat ist Grooming“. Aber LIWC zeigt dir, dass es z. B. an erhöhter Nutzung von „social processes“, „present focus“ oder „cognitive words“ liegt.
➤ SHAP-Werte können zeigen, dass bestimmte LIWC-Kategorien systematisch zur Entscheidung beitragen.

3. Edge Cases und Ablation-Study
Du kannst gezielt analysieren, ob RoBERTa bei bestimmten Subgruppen (z. B. kurze Chats, weniger explizite Sprache, viele Slangwörter) schlechter performt – und ob LIWC dort einen Beitrag liefert.

➤ Beispiel: Wenn du Fälle mit hohem „Authenticity“-Score (LIWC) betrachtest, versagt RoBERTa vielleicht häufiger, weil Sprache „echter“ wirkt.
➤ Diese „Ablation nach Textmerkmalen“ ist wissenschaftlich extrem interessant.



\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%